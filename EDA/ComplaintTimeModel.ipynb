{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complaints Time to respond model\n",
    "\n",
    "We will try to predict the time to respond model using word embbeding features from our fasttext model trained on complaints description.\n",
    "We hope to have a good model to inform companies if they are lagging behind our excelling in comparison to their competitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lois/pojetos/ds4a/notebook\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 51655 reviews!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'FastText' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-111611b7a179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fasttext_v0/fasttext.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FastText' is not defined"
     ]
    }
   ],
   "source": [
    "from src.loading import load_dataset\n",
    "from src.cleaning import build_df_from_RA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Strip accents and lower text string\n",
    "    :param text: (str) text to be cleaned\n",
    "    :return: (str) cleaned text\n",
    "    \"\"\"\n",
    "    text = strip_accents(text)\n",
    "    text = text.lower().strip()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return text\n",
    "\n",
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\b[0-9]+\\b', '', text)\n",
    "\n",
    "def tokenize(data, sep=None):\n",
    "    if sep is not None:\n",
    "        return data.split(sep)\n",
    "    return data.split()\n",
    "\n",
    "# Load data\n",
    "df = build_df_from_RA(load_dataset(\"dataset\"))\n",
    "df[\"normalized_text\"] = df.apply(lambda row: f\"{remove_numbers(normalize_text(row['title']))} {remove_numbers(normalize_text(row['description']))}\", axis=1)\n",
    "print(f\"We have a total of {df.shape[0]} reviews!\")\n",
    "\n",
    "# Load model\n",
    "model = FT_gensim.load(\"fasttext_v0/fasttext.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37883, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De-biasing response days variable\n",
    "df = df.loc[(df.days_to_first_contact < 20)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokens_sq = [tokenize(i) for i in texts.values]\n",
    "len(tokens_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
